{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix factorization of an explicit feedback (ratings) matrix\n",
    "\n",
    "The goal of this exercise is to generate recommendations for movies using Matric Factorization (MF) and Neural Network MF. \n",
    "\n",
    "See also:\n",
    "* https://arxiv.org/abs/1708.05031\n",
    "* http://hameddaily.blogspot.fr/2016/12/simple-matrix-factorization-with.html\n",
    "* https://nipunbatra.github.io/blog/2017/recommend-keras.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow==2.0.0-beta0\n",
    "!pip install -q matplotlib\n",
    "!pip install -q pandas\n",
    "!pip install -q numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "The small MovieLens dataset: https://grouplens.org/datasets/movielens/100k/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "\n",
    "resp = urlopen(\"http://files.grouplens.org/datasets/movielens/ml-100k.zip\")\n",
    "zipfile = ZipFile(BytesIO(resp.read()))\n",
    "file = 'ml-100k/u.data'\n",
    "df = pd.read_csv(zipfile.open(file), low_memory=False, skiprows=[0], sep='\\t', names=['user', 'item', 'rate', 'time'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the dataset into training and test subset. We remove the mean rating.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(42)\n",
    "# split data into train and test set\n",
    "msk = numpy.random.rand(len(df)) < 0.7\n",
    "df_train = df[msk]\n",
    "df_test = df[~msk]\n",
    "\n",
    "user_index = [x-1 for x in df_train.user.values]\n",
    "item_index = [x-1 for x in df_train.item.values]\n",
    "user_index_test = [x-1 for x in df_test.user.values]\n",
    "item_index_test = [x-1 for x in df_test.item.values]\n",
    "\n",
    "rates = df_train.rate.values \n",
    "rates_test = df_test.rate.values\n",
    "\n",
    "num_ratings = len(rates)\n",
    "num_ratings_test = len(rates_test)\n",
    "mean_rating = numpy.mean(rates)\n",
    "mean_rating_test = numpy.mean(rates_test)\n",
    "\n",
    "rates = rates - mean_rating\n",
    "rates_test = rates_test - mean_rating\n",
    "\n",
    "print (\"Mean (train) rating = \" + str(mean_rating))\n",
    "print (\"Number of ratings (train/val/total) = \" + str(num_ratings) + \"/\" + str(num_ratings_test) + \"/\" + str(num_ratings + num_ratings_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization\n",
    "\n",
    "In matrix factorization user rating r is formulated as an inner product of two latent vectors $u$ and $v$  which are two latent vectors in same space to represent the user interest and movie feature respectively.\n",
    "\n",
    "$r=u^Tv$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "Image(url= \"https://4.bp.blogspot.com/-95QD5t9Lha4/Wd7uWnBZBeI/AAAAAAAADg4/xB4VnnxM0UgUp15lNmB3aHCXYGejpm4OACLcBGAs/s1600/matrix_factorization.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent space\n",
    "\n",
    "We define these two latent variables in TensorFlow as follows: $U$ shows latent representation of user interest and $P$ that represents the latent values for items.\n",
    "\n",
    "The dimension of the latent space 'feature_len' is a parameter of the method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "feature_len = 10\n",
    "\n",
    "num_users = len(numpy.unique(df.user.values)) \n",
    "num_items = len(numpy.unique(df.item.values)) \n",
    "\n",
    "print(\"Number of users is {}\".format(num_users))\n",
    "print(\"Number of movies is {}\".format(num_items))\n",
    "print(\"The latent space has dimension {}\".format(feature_len))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "We define the user and item matrices and use their product to compute ratings R. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product embedding\n",
    "item_input = tf.keras.layers.Input(shape=[1],name='Item')\n",
    "item_embedding = tf.keras.layers.Embedding(num_items, feature_len, name='Item-Embedding')(item_input)\n",
    "item_vec = tf.keras.layers.Flatten(name='FlattenItems')(item_embedding)\n",
    "\n",
    "# user embedding\n",
    "user_input = tf.keras.layers.Input(shape=[1],name='User')\n",
    "user_embedding = tf.keras.layers.Embedding(num_users, feature_len, name='User-Embedding')(user_input)\n",
    "user_vec = tf.keras.layers.Flatten(name='FlattenUsers')(user_embedding)\n",
    "\n",
    "# rating\n",
    "#user_vec_transp = tf.transpose(user_vec)\n",
    "result = tf.keras.layers.dot([item_vec, user_vec], axes=1, name='DotProduct')\n",
    "\n",
    "# initialize Keras model \n",
    "model = tf.keras.Model([user_input, item_input], result)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and optimizer\n",
    "\n",
    "To learn model parameters, we optimize the model with respect to mean squared error loss. As the optimization algorithm we use stochastic gradient descent (SGD) or Adam optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "# learning rate\n",
    "lr = 0.001\n",
    "learning_rate = tf.optimizers.schedules.ExponentialDecay(lr, decay_steps=100000,\n",
    "    decay_rate=0.96, staircase=True)\n",
    "\n",
    "optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "#optimizer = tf.optimizers.SGD(learning_rate=lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "We define the accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define accuracy\n",
    "threshold = 1.0\n",
    "\n",
    "def accuracy(desired_rates, predicted_rates):\n",
    "    diff_op = tf.subtract(predicted_rates, desired_rates, name='trainig_diff')\n",
    "    # Just measure the absolute difference against the threshold\n",
    "    good = tf.less(tf.abs(diff_op), threshold)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(good, tf.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model with the optimizerm, loss and the tracking metrics\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[accuracy])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "During training, we evaluate the accuracy on a validation set (validation_split=0.1).\n",
    "\n",
    "Question: Choose the number of epochs such that the model does not overfit the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberEpochs = 10\n",
    "history = model.fit([user_index, item_index], rates, epochs=numberEpochs, verbose=1, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the training history\n",
    "We can visualize the training and validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history):\n",
    "    pd.Series(history.history['loss']).plot(logy=True, label='Training loss')\n",
    "    pd.Series(history.history['val_loss']).plot(logy=True, label='Validation loss')\n",
    "    \n",
    "    pd.Series(history.history['accuracy']).plot(logy=True, label='Training accuracy')\n",
    "    pd.Series(history.history['val_accuracy']).plot(logy=True, label='Validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on the test dataset\n",
    "Let's look at the predictions for some users from the testset. We also compute RMSE on the testset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "nr_sampled_users = 10\n",
    "\n",
    "for index in numpy.random.choice(range(len(user_index_test)), size=nr_sampled_users):\n",
    "    u = [user_index_test[index]]\n",
    "    p = [item_index_test[index]]\n",
    "    r = rates_test[index] + mean_rating\n",
    "\n",
    "    rhat = model.predict([u, p]) + mean_rating_test\n",
    "\n",
    "    print (\"rating for user \" + str(u) + \" for item \" + str(p) + \" is \" + str(r) + \" and our prediction is: \" + str(rhat[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def compute_RMSE(model, user_index_test, item_index_test):\n",
    "    predicted_rates_test = model.predict([user_index_test, item_index_test])\n",
    "    \n",
    "    return mean_absolute_error(rates_test, predicted_rates_test)\n",
    "\n",
    "err_test = compute_RMSE(model, user_index_test, item_index_test)\n",
    "print(\"Mean absolute error on the test set: {}\".format(err_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate recommendations from the trained model for a list of users\n",
    "\n",
    "Noe that we have trained a model to predict ratings, we generate recommendations for every user by ranking the movies by the predicted rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_recommendations(model, df, listOfUsers, nrRecommendations=20):\n",
    "    \n",
    "    item_index = numpy.array(numpy.unique(df.item.values))-1\n",
    "    recommendations_set = {}\n",
    "    \n",
    "    for user in listOfUsers:\n",
    "        user_index = numpy.ones(len(item_index)) * user\n",
    "        predicted_rates = model.predict([user_index, item_index]) #+ mean_rating\n",
    "        \n",
    "        ranked_items_idx = numpy.argsort(predicted_rates, axis=0)[::-1].squeeze()\n",
    "        ranked_items = item_index[ranked_items_idx] \n",
    "        recommendations_set[user] = ranked_items[:nrRecommendations]\n",
    "        \n",
    "    return recommendations_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create validation set for every user\n",
    "We first create a validation set for every user which consists of all the products that the user rated higher than 3.5 (the value of the mean rate).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validation_set(df, minRate=3.5, k=5):\n",
    "    validation_set = {}\n",
    "    \n",
    "    for user in numpy.unique(df['user'].values) - 1:\n",
    "        rated_items = df[df['user'] == user]['item'].values -1\n",
    "        rates = df[df['user'] == user]['rate'].values\n",
    "\n",
    "        best_ranked_items = rated_items[numpy.where(rates > minRate)[0]]\n",
    "        if len(best_ranked_items) >= k:\n",
    "            validation_set[user] = best_ranked_items\n",
    "            \n",
    "    return validation_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute precision@k \n",
    "\n",
    "In the context of recommendation systems we are most likely interested in recommending top-N items to the user. So it makes more sense to compute precision and recall metrics in the first N items instead of all the items. Thus the notion of precision at k where k is a user definable integer that is set by the user to match the top-N recommendations objective.\n",
    "\n",
    "Precision at k is the proportion of recommended items in the top-k set that are relevant.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precisionAtK(validations_set, recommendations_set, k=5):\n",
    "    \n",
    "    res = []\n",
    "    for user in validations_set.keys():\n",
    "        \n",
    "        v = validations_set[user]\n",
    "        r = recommendations_set[user][:k]\n",
    "        \n",
    "        ans = len(numpy.intersect1d(v, r)) / k\n",
    "        res.append(ans)\n",
    "\n",
    "    return numpy.mean(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precisionAtK_from_recommendations(model, df_test, validation_set=None, nrRecommendations=20, k=10):\n",
    "    \"\"\"\n",
    "    Compute precisionAtK from recommendations and validation set. Generate recommendations applying \\\n",
    "    'model' to dataset 'df_test'. \n",
    "    \"\"\"\n",
    "    if validation_set is None:\n",
    "        validation_set = create_validation_set(df_test, minRate=3.5, k=k)\n",
    "        \n",
    "    recommendations_set = create_recommendations(model, df_test, \\\n",
    "                                              validation_set.keys(), nrRecommendations=nrRecommendations)\n",
    "    precision = precisionAtK(validation_set, recommendations_set, k=k)\n",
    "    \n",
    "    return precision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "validation_set = create_validation_set(df_test, minRate=3.5, k=k)\n",
    "\n",
    "precision = compute_precisionAtK_from_recommendations(model, df_test, validation_set=validation_set, \\\n",
    "                                                      nrRecommendations=20, k=k)\n",
    "print(\"MF: Precision@{} is {}\".format(k, precision))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Experiment with the parameter choice of the MF model and evaluate the setting in RMSE and Precision@5. Compare various settings in the ResultsTable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultsTable():\n",
    "    def __init__(self):\n",
    "        self.columns = [\"name\", \"RMSE\", \"Precision@5\"]\n",
    "        self.df = pd.DataFrame(columns=self.columns)\n",
    "        \n",
    "    def add(self, name=\"experimentName\", rmse=None, precision=None, overwrite=False):\n",
    "        \n",
    "        data ={\"name\":name, \"RMSE\":rmse, \"Precision@5\": precision}\n",
    "        res = pd.Series(data, self.columns, name=name)\n",
    "        \n",
    "        if len(self.df[self.df.name == name]) > 0:\n",
    "            if not overwrite:\n",
    "                raise Exception(\"Error: experiments name already exists. Change the name or set overwrite to True.\")\n",
    "            else:\n",
    "                self.df = self.df.drop(self.df[self.df.name == name].index[0])\n",
    "                self.df = self.df.append(res,  ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            self.df = self.df.append(res,  ignore_index=True)\n",
    "\n",
    "        \n",
    "    def show(self):\n",
    "        display(self.df)\n",
    "\n",
    "table = ResultsTable()        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the RMSE and Precision@5 and add it to the results table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_test = compute_RMSE(model, user_index_test, item_index_test)\n",
    "\n",
    "precision = compute_precisionAtK_from_recommendations(model, df_test, validation_set=validation_set, nrRecommendations=20, k=5)\n",
    "print(\"MF: Precision@{} is {}\".format(5, precision))\n",
    "print(\"MF: RMSE is {}\".format(err_test))\n",
    "\n",
    "table.add(name=\"MF\", rmse=err_test, precision=precision, overwrite=True)\n",
    "table.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## example:\n",
    "experiment_name = \"MF_\" + \"regUserItemL2\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: \n",
    "- choose the regularization\n",
    " https://keras.io/regularizers/\n",
    "- loss \n",
    "- optimizer\n",
    "- learning rate\n",
    "- number of epochs\n",
    "\n",
    "Benchmark several experiments with different hyperparameters \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regularizers\n",
    "no_regularizer = None\n",
    "regularizer_l2 = tf.keras.regularizers.l2(0.0001)\n",
    "regularizer_l1 = tf.keras.regularizers.l1(0.0001)\n",
    "regularizer_l1l2 = tf.keras.regularizers.l1_l2(0.0001)\n",
    "\n",
    "regularizer_user = regularizer_l2\n",
    "regularizer_product = regularizer_l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product embedding\n",
    "item_input = tf.keras.layers.Input(shape=[1],name='Item')\n",
    "\n",
    "################ EMBEDDING AND REGULARIZER ##########################################################################\n",
    "item_embedding = tf.keras.layers.Embedding(num_items, feature_len, name='Item-Embedding', \\\n",
    "                                          embeddings_regularizer=regularizer_product)(item_input)\n",
    "#################################################################################################\n",
    "\n",
    "item_vec = tf.keras.layers.Flatten(name='FlattenItems')(item_embedding)\n",
    "\n",
    "# user embedding\n",
    "user_input = tf.keras.layers.Input(shape=[1],name='User')\n",
    "################ EMBEDDING AND REGULARIZER ##########################################################################\n",
    "user_embedding = tf.keras.layers.Embedding(num_users, feature_len,name='User-Embedding', \\\n",
    "                                          embeddings_regularizer=regularizer_user)(user_input)\n",
    "#################################################################################################\n",
    "\n",
    "user_vec = tf.keras.layers.Flatten(name='FlattenUsers')(user_embedding)\n",
    "\n",
    "# rating\n",
    "result = tf.keras.layers.dot([item_vec, user_vec], axes=1, name='DotProduct')\n",
    "\n",
    "# initialize Keras model \n",
    "model = tf.keras.Model([user_input, item_input], result)\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the loss \n",
    "# see https://keras.io/losses/\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "# learning rate\n",
    "lr = 0.001\n",
    "learning_rate = tf.optimizers.schedules.ExponentialDecay(lr, decay_steps=100000,\n",
    "    decay_rate=0.96, staircase=True)\n",
    "\n",
    "# choose the optimizer\n",
    "optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "#optimizer = tf.optimizers.SGD(learning_rate=lr)\n",
    "\n",
    "\n",
    "# compile the model with the optimizerm, loss and the tracking metrics\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[accuracy])\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "numberEpochs = 10\n",
    "history = model.fit([user_index, item_index], rates, epochs=numberEpochs, verbose=1, validation_split=0.1)\n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_test = compute_RMSE(model, user_index_test, item_index_test)\n",
    "\n",
    "precision = compute_precisionAtK_from_recommendations(model, df_test, validation_set=validation_set, \\\n",
    "                                                      nrRecommendations=20, k=5)\n",
    "print(\"MF: Precision@{} is {}\".format(5, precision))\n",
    "print(\"MF: RMSE is {}\".format(err_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.add(name=experiment_name, rmse=err_test, precision=precision, overwrite=True)\n",
    "table.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table.add(name=\"experiment_l1regularization\", rmse=err_test, precision=precision)\n",
    "table.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks for recommendation\n",
    "Create a simple neural network for recommendation, or for estimating rating! This model is very similar to the earlier matrix factorisation models, but differs in the following ways:\n",
    "\n",
    "- Instead of taking a dot product of the user and the item embedding, we concatenate them and use them as features for our neural network. Thus, we are not constrained to the dot product way of combining the embeddings, and can learn complex non-linear relationships.\n",
    "- We can now have a different dimension of user and item embeddings. This can be useful if one dimension is larger than the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"NNMF\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_latent_factors_user = 50\n",
    "n_latent_factors_item = 100\n",
    "\n",
    "item_input = tf.keras.layers.Input(shape=[1],name='Item')\n",
    "item_embedding = tf.keras.layers.Embedding(num_items, n_latent_factors_item, name='Item-Embedding')(item_input)\n",
    "item_vec = tf.keras.layers.Flatten(name='FlattenItems')(item_embedding)\n",
    "item_vec = tf.keras.layers.Dropout(0.2)(item_vec)\n",
    "\n",
    "user_input = tf.keras.layers.Input(shape=[1],name='User')\n",
    "user_embedding = tf.keras.layers.Embedding(num_users, n_latent_factors_user,name='User-Embedding')(user_input)\n",
    "user_vec = tf.keras.layers.Flatten(name='FlattenUsers')(user_embedding)\n",
    "user_vec = tf.keras.layers.Dropout(0.2)(user_vec)\n",
    "\n",
    "concat = tf.keras.layers.concatenate([item_vec, user_vec], name='Concat')\n",
    "concat = tf.keras.layers.Dropout(0.2)(concat)\n",
    "full1 = tf.keras.layers.Dense(200,name='FullyConnected', activation='relu')(concat)\n",
    "full1 = tf.keras.layers.Dropout(0.2,name='Dropout')(full1)\n",
    "# full2 = tf.keras.layers.Dense(100,name='FullyConnected-1', activation='relu')(full1)\n",
    "# full2 = tf.keras.layers.Dropout(0.2,name='Dropout')(full2)\n",
    "# full3 = tf.keras.layers.Dense(50,name='FullyConnected-2', activation='relu')(full2)\n",
    "# full3 = tf.keras.layers.Dropout(0.2,name='Dropout')(full3)\n",
    "# full4 = tf.keras.layers.Dense(20,name='FullyConnected-3', activation='relu')(full3)\n",
    "\n",
    "result = tf.keras.layers.Dense(1, name='Activation')(full1)\n",
    "\n",
    "lr = 0.0001\n",
    "learning_rate = tf.optimizers.schedules.ExponentialDecay(lr, decay_steps=100000,\n",
    "    decay_rate=0.96, staircase=True)\n",
    "\n",
    "adam = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "model_NN = tf.keras.Model([user_input, item_input], result)\n",
    "model_NN.compile(optimizer=adam, loss= 'mean_squared_error', metrics=[accuracy])\n",
    "model_NN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberEpochs = 10\n",
    "print_log = 1\n",
    "history_NN = model_NN.fit([user_index, item_index], rates, epochs=numberEpochs, \\\n",
    "                          verbose=print_log, validation_split=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_NN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"NNMF\"\n",
    "err_test = compute_RMSE(model_NN, user_index_test, item_index_test)\n",
    "\n",
    "precision = compute_precisionAtK_from_recommendations(model_NN, df_test, validation_set=validation_set, \\\n",
    "                                                      nrRecommendations=20, k=5)\n",
    "print(\"MF: Precision@{} is {}\".format(5, precision))\n",
    "print(\"MF: RMSE is {}\".format(err_test))\n",
    "\n",
    "table.add(name=experiment_name, rmse=err_test, precision=precision, overwrite=True)\n",
    "table.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "Change the model parameters, for example:\n",
    "- Change the number of layers of the NN\n",
    "- Remove/add dropout\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design a simple baseline:  predict average rate per item and recommend items with the highest rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbo = df_test[[\"item\", \"rate\"]].groupby(\"item\").mean().reset_index()\n",
    "df_gbo = pd.merge(df_test, gbo, on=\"item\", suffixes=('', '_gbo'))\n",
    "display(df_gbo[df_gbo.item == 1].head())\n",
    "predicted_rates_gbo_test = df_gbo.rate_gbo.values\n",
    "\n",
    "err_gbo_test = mean_absolute_error(rates_test + mean_rating_test, predicted_rates_gbo_test)\n",
    "\n",
    "print(\"Mean absolute error on the test set: {}\".format(err_gbo_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_highest_rates(df, userList, nrRecommendations=10):\n",
    "    gbo_set = {}\n",
    "    \n",
    "    # compute mean rating per item\n",
    "    all_items = numpy.unique(df['item'].values)\n",
    "    gbos = df.groupby(\"item\").mean().rate.reset_index().sort_values(by=\"rate\", ascending=False).item.values[:nrRecommendations]\n",
    "    \n",
    "    for user in userList:\n",
    "        gbo_set[user] = gbos\n",
    "            \n",
    "    return gbo_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_rates_baseline = recommend_highest_rates(df, validation_set.keys(), nrRecommendations=20)\n",
    "\n",
    "precision_baseline = precisionAtK(validation_set, highest_rates_baseline, k=5)\n",
    "print(\"Baseline: Precision@{} is {}\".format(5, precision_baseline))\n",
    "table.add(name=\"gbo\", rmse=err_gbo_test, precision=precision_baseline, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(table.df.sort_values(by=\"RMSE\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(table.df.sort_values(by=\"Precision@5\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
