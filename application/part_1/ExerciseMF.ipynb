{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution: MF of an explicit feedback (ratings) matrix\n",
    "\n",
    "The goal of this exercise is to compare a simple Matric Factorization (MF) and Neural Network Matrix Factorization. \n",
    "\n",
    "\n",
    "**Given:**\n",
    "- data loader and matrix initialization code \n",
    "- default params settings, training and evaluation \n",
    "\n",
    "\n",
    "**Original sources:** \n",
    "\n",
    "\n",
    "http://hameddaily.blogspot.fr/2016/12/simple-matrix-factorization-with.html\n",
    "\n",
    "https://nipunbatra.github.io/blog/2017/recommend-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow==2.0.0-beta0\n",
    "!pip install -q matplotlib\n",
    "!pip install -q pandas\n",
    "!pip install -q numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "\n",
    "resp = urlopen(\"http://files.grouplens.org/datasets/movielens/ml-100k.zip\")\n",
    "zipfile = ZipFile(BytesIO(resp.read()))\n",
    "file = 'ml-100k/u.data'\n",
    "df = pd.read_csv(zipfile.open(file), low_memory=False, skiprows=[0], sep='\\t', names=['user', 'item', 'rate', 'time'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(42)\n",
    "# split data into train and test set\n",
    "msk = numpy.random.rand(len(df)) < 0.7\n",
    "df_train = df[msk]\n",
    "df_test = df[~msk]\n",
    "\n",
    "user_index = [x-1 for x in df_train.user.values]\n",
    "item_index = [x-1 for x in df_train.item.values]\n",
    "user_index_test = [x-1 for x in df_test.user.values]\n",
    "item_index_test = [x-1 for x in df_test.item.values]\n",
    "\n",
    "rates = df_train.rate.values \n",
    "rates_test = df_test.rate.values\n",
    "\n",
    "num_ratings = len(rates)\n",
    "num_ratings_test = len(rates_test)\n",
    "mean_rating = numpy.mean(rates)\n",
    "mean_rating_test = numpy.mean(rates_test)\n",
    "\n",
    "rates = rates - mean_rating\n",
    "rates_test = rates_test - mean_rating_test\n",
    "\n",
    "\n",
    "print (\"Mean (train) rating = \" + str(mean_rating))\n",
    "print (\"Number of ratings (train/val/total) = \" + str(num_ratings) + \"/\" + str(num_ratings_test) + \"/\" + str(num_ratings + num_ratings_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MF model: define the user and item embeddings\n",
    "Define/initialize the User and Item matrices and use their product to compute ratings R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "feature_len = 10\n",
    "\n",
    "num_users = len(numpy.unique(df.user.values)) \n",
    "num_items = len(numpy.unique(df.item.values)) \n",
    "\n",
    "print(\"Number of users is {}\".format(num_users))\n",
    "print(\"Number of movies is {}\".format(num_items))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product embedding\n",
    "item_input = tf.keras.layers.Input(shape=[1],name='Item')\n",
    "item_embedding = tf.keras.layers.Embedding(num_items, feature_len, name='Item-Embedding')(item_input)\n",
    "item_vec = tf.keras.layers.Flatten(name='FlattenItems')(item_embedding)\n",
    "\n",
    "# user embedding\n",
    "user_input = tf.keras.layers.Input(shape=[1],name='User')\n",
    "user_embedding = tf.keras.layers.Embedding(num_users, feature_len, name='User-Embedding')(user_input)\n",
    "user_vec = tf.keras.layers.Flatten(name='FlattenUsers')(user_embedding)\n",
    "\n",
    "# rating\n",
    "#user_vec_transp = tf.transpose(user_vec)\n",
    "result = tf.keras.layers.dot([item_vec, user_vec], axes=1, name='DotProduct')\n",
    "\n",
    "# initialize Keras model \n",
    "model = tf.keras.Model([user_input, item_input], result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the loss \n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "# learning rate\n",
    "lr = 0.001\n",
    "learning_rate = tf.optimizers.schedules.ExponentialDecay(lr, decay_steps=100000,\n",
    "    decay_rate=0.96, staircase=True)\n",
    "\n",
    "\n",
    "optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "#optimizer = tf.optimizers.SGD(learning_rate=lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define accuracy\n",
    "threshold = 1.0\n",
    "\n",
    "def accuracy(desired_rates, predicted_rates):\n",
    "    diff_op = tf.subtract(predicted_rates, desired_rates, name='trainig_diff')\n",
    "    # Just measure the absolute difference against the threshold\n",
    "    good = tf.less(tf.abs(diff_op), threshold)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(good, tf.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model with the optimizerm, loss and the tracking metrics\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[accuracy])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberEpochs = 10\n",
    "history = model.fit([user_index, item_index], rates, epochs=numberEpochs, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the training and validation loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history):\n",
    "    pd.Series(history.history['loss']).plot(logy=True, label='Training loss')\n",
    "    pd.Series(history.history['val_loss']).plot(logy=True, label='Validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Train Error\")\n",
    "    plt.show()\n",
    "    \n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test dataset and compute RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "nr_sampled_users = 10\n",
    "\n",
    "for index in numpy.random.choice(range(num_users), size=nr_sampled_users):\n",
    "    u, p, r = df[['user', 'item', 'rate']].values[index]\n",
    "    learnt_product_embedding = model.get_layer(name='Item-Embedding').get_weights()[0]\n",
    "    learnt_user_embedding = model.get_layer(name='User-Embedding').get_weights()[0]\n",
    "\n",
    "    predicted_rates = numpy.dot(learnt_user_embedding, learnt_product_embedding.T)\n",
    "\n",
    "    rhat = tf.gather(tf.gather(tf.add(predicted_rates, mean_rating), u-1), p-1)\n",
    "    print (\"rating for user \" + str(u) + \" for item \" + str(p) + \" is \" + str(r) + \" and our prediction is: \" + str(rhat.numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def compute_RMSE(model, user_index_test, item_index_test):\n",
    "    predicted_rates_test = model.predict([user_index_test, item_index_test])\n",
    "    \n",
    "    return mean_absolute_error(rates_test, predicted_rates_test)\n",
    "\n",
    "err_test = compute_RMSE(model, user_index_test, item_index_test)\n",
    "print(\"Mean absolute error on the test set: {}\".format(err_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate recommendations from the trained model for a list of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_recommendations(model, df, listOfUsers, nrRecommendations=20):\n",
    "    \n",
    "    item_index = numpy.array(numpy.unique(df.item.values)) - 1\n",
    "    \n",
    "    recommendations_set = {}\n",
    "    \n",
    "    for user in listOfUsers:\n",
    "        user_index = numpy.ones(len(item_index)) * user\n",
    "        predicted_rates = model.predict([user_index, item_index]) \n",
    "    \n",
    "        ranked_items_idx = numpy.argsort(predicted_rates, axis=0)[::-1].squeeze()\n",
    "        ranked_items = item_index[ranked_items_idx]\n",
    "        \n",
    "        recommendations_set[user] = ranked_items[:nrRecommendations]\n",
    "        \n",
    "    return recommendations_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and compute Precision@K score\n",
    "\n",
    "We first create a validation set for every user which consists of all the products that the user rated higher than 3.5 (the value of the mean rate).\n",
    "\n",
    "We then compute precistion@K for our recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create validation set for every user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validation_set(df, minRate=3.5):\n",
    "    validation_set = {}\n",
    "    \n",
    "    for user in numpy.unique(df['user'].values) - 1:\n",
    "        rated_items = df[df['user'] == user]['item'].values\n",
    "        rates = df[df['user'] == user]['rate'].values\n",
    "\n",
    "        best_ranked_items = rated_items[numpy.where(rates > minRate)[0]]\n",
    "        if len(best_ranked_items) > 0:\n",
    "            validation_set[user] = best_ranked_items\n",
    "            \n",
    "    return validation_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute precision@k using the recommendations and the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precisionAtK(validations_set, recommendations_set, k=3):\n",
    "\n",
    "    precision = []\n",
    "    for user in validations_set.keys():\n",
    "\n",
    "        precision.append(tf.keras.metrics.top_k_categorical_accuracy(\n",
    "        validations_set[user][numpy.newaxis],\n",
    "        recommendations_set[user][numpy.newaxis],\n",
    "        k=k\n",
    "    ).numpy() / k)\n",
    "\n",
    "    return numpy.mean(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precisionAtK_from_recommendations(model, df_test, validation_set=None, nrRecommendations=20, k=10):\n",
    "    if validation_set is None:\n",
    "        validation_set = create_validation_set(df_test, minRate=3.5)\n",
    "        \n",
    "    recommendations_set = create_recommendations(model, df_test, \\\n",
    "                                              validation_set.keys(), nrRecommendations=nrRecommendations)\n",
    "    precision = precisionAtK(validation_set, recommendations_set, k=k)\n",
    "    \n",
    "    return precision\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = create_validation_set(df_test, minRate=3.5)\n",
    "# recommendations_set = create_recommendations(model, user_index_test, item_index_test, \\\n",
    "#                                               validation_set.keys(), nrRecommendations=20)\n",
    "\n",
    "precision = compute_precisionAtK_from_recommendations(model, df_test, validation_set=validation_set, nrRecommendations=20, k=5)\n",
    "print(\"MF: Precision@{} is {}\".format(5, precision))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### how does the precision@k vary for k\n",
    "\n",
    "# recommendations_set = create_recommendations(model, df_test, \\\n",
    "#                                               validation_set.keys(), nrRecommendations=100)\n",
    "# prec = []\n",
    "# kvect = range(1, 100, 10)\n",
    "# for k in kvect:\n",
    "#     print(k)\n",
    "#     precision = precisionAtK(validation_set, recommendations_set, k=k)\n",
    "#     print(\"MF: Precision@{} is {}\".format(k, precision))\n",
    "#     prec.append(precision)\n",
    "\n",
    "# plt.plot(kvect, prec)\n",
    "# plt.xlabel(\"k\")\n",
    "# plt.ylabel(\"Precision@k\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Experiment with the parameter choice of the MF model and evaluate the setting in RMSE and Precision@5. Compare various settings in the ResultsTable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultsTable():\n",
    "    def __init__(self):\n",
    "        self.columns = [\"name\", \"RMSE\", \"Precision@5\"]\n",
    "        self.df = pd.DataFrame(columns=self.columns)\n",
    "        \n",
    "    def add(self, name=\"experimentName\", rmse=None, precision=None, overwrite=False):\n",
    "        \n",
    "        data ={\"name\":name, \"RMSE\":rmse, \"Precision@5\": precision}\n",
    "        res = pd.Series(data, self.columns, name=name)\n",
    "        \n",
    "        if len(self.df[self.df.name == name]) > 0:\n",
    "            if not overwrite:\n",
    "                print(\"Error: name already exists. Change name or set overwrite to True.\")\n",
    "            else:\n",
    "                self.df = self.df.drop(self.df[self.df.name == name].index[0])\n",
    "                self.df = self.df.append(res,  ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            self.df = self.df.append(res,  ignore_index=True)\n",
    "\n",
    "        \n",
    "    def show(self):\n",
    "        display(self.df)\n",
    "\n",
    "table = ResultsTable()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the RMSE and Precision@5 and add it to the results table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_test = compute_RMSE(model, user_index_test, item_index_test)\n",
    "\n",
    "precision = compute_precisionAtK_from_recommendations(model, df_test, validation_set=validation_set, nrRecommendations=20, k=5)\n",
    "print(\"MF: Precision@{} is {}\".format(5, precision))\n",
    "print(\"MF: RMSE is {}\".format(err_test))\n",
    "\n",
    "table.add(name=\"MF\", rmse=err_test, precision=precision, overwrite=False)\n",
    "table.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: choose the regularization\n",
    "Regularizers: see https://keras.io/regularizers/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## example:\n",
    "experiment_name = \"MF_\" + \"regUserItemL2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regularizers\n",
    "no_regularizer = None\n",
    "regularizer_l2 = tf.keras.regularizers.l2(0.0001)\n",
    "regularizer_l1 = tf.keras.regularizers.l1(0.0001)\n",
    "regularizer_l1l2 = tf.keras.regularizers.l1_l2(0.0001)\n",
    "\n",
    "regularizer_user = regularizer_l2\n",
    "regularizer_product = regularizer_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product embedding\n",
    "item_input = tf.keras.layers.Input(shape=[1],name='Item')\n",
    "\n",
    "################ EMBEDDING AND REGULARIZER ##########################################################################\n",
    "item_embedding = tf.keras.layers.Embedding(num_items + 1, feature_len, name='Item-Embedding', \\\n",
    "                                          embeddings_regularizer=regularizer_product)(item_input)\n",
    "#################################################################################################\n",
    "\n",
    "item_vec = tf.keras.layers.Flatten(name='FlattenItems')(item_embedding)\n",
    "\n",
    "# user embedding\n",
    "user_input = tf.keras.layers.Input(shape=[1],name='User')\n",
    "################ EMBEDDING AND REGULARIZER ##########################################################################\n",
    "user_embedding = tf.keras.layers.Embedding(num_users + 1, feature_len,name='User-Embedding', \\\n",
    "                                          embeddings_regularizer=regularizer_user)(user_input)\n",
    "#################################################################################################\n",
    "\n",
    "user_vec = tf.keras.layers.Flatten(name='FlattenUsers')(user_embedding)\n",
    "\n",
    "# rating\n",
    "result = tf.keras.layers.dot([item_vec, user_vec], axes=1, name='DotProduct')\n",
    "\n",
    "# initialize Keras model \n",
    "model = tf.keras.Model([user_input, item_input], result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the loss \n",
    "## MeanAbsoluteError, MeanSquaredError, MeanSquaredLogarithmicError; see https://keras.io/losses/\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "# learning rate\n",
    "lr = 0.001\n",
    "learning_rate = tf.optimizers.schedules.ExponentialDecay(lr, decay_steps=100000,\n",
    "    decay_rate=0.96, staircase=True)\n",
    "\n",
    "# choose the optimizer\n",
    "optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "#optimizer = tf.optimizers.SGD(learning_rate=lr)\n",
    "\n",
    "\n",
    "# compile the model with the optimizerm, loss and the tracking metrics\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[accuracy])\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "numberEpochs = 10\n",
    "history = model.fit([user_index, item_index], rates, epochs=numberEpochs, verbose=1, validation_split=0.1)\n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_test = compute_RMSE(model, user_index_test, item_index_test)\n",
    "\n",
    "precision = compute_precisionAtK_from_recommendations(model, df_test, validation_set=validation_set, nrRecommendations=20, k=5)\n",
    "print(\"MF: Precision@{} is {}\".format(5, precision))\n",
    "print(\"MF: RMSE is {}\".format(err_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add results into the result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.add(name=experiment_name, rmse=err_test, precision=precision, overwrite=True)\n",
    "table.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: Benchmark several experiments with different hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table.add(name=\"experiment_l1regularization\", rmse=err_test, precision=precision)\n",
    "table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks for recommendation\n",
    "Create a simple neural network for recommendation, or for estimating rating! This model is very similar to the earlier matrix factorisation models, but differs in the following ways:\n",
    "\n",
    "- Instead of taking a dot product of the user and the item embedding, we concatenate them and use them as features for our neural network. Thus, we are not constrained to the dot product way of combining the embeddings, and can learn complex non-linear relationships.\n",
    "- We can now have a different dimension of user and item embeddings. This can be useful if one dimension is larger than the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"NNMF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_latent_factors_user = 5\n",
    "n_latent_factors_item = 8\n",
    "\n",
    "item_input = tf.keras.layers.Input(shape=[1],name='Item')\n",
    "item_embedding = tf.keras.layers.Embedding(num_items, n_latent_factors_item, name='Item-Embedding')(item_input)\n",
    "item_vec = tf.keras.layers.Flatten(name='FlattenItems')(item_embedding)\n",
    "item_vec = tf.keras.layers.Dropout(0.2)(item_vec)\n",
    "\n",
    "user_input = tf.keras.layers.Input(shape=[1],name='User')\n",
    "user_embedding = tf.keras.layers.Embedding(num_users, n_latent_factors_user,name='User-Embedding')(user_input)\n",
    "user_vec = tf.keras.layers.Flatten(name='FlattenUsers')(user_embedding)\n",
    "user_vec = tf.keras.layers.Dropout(0.2)(user_vec)\n",
    "\n",
    "concat = tf.keras.layers.concatenate([item_vec, user_vec], name='Concat')\n",
    "concat_dropout = tf.keras.layers.Dropout(0.2)(concat)\n",
    "dense = tf.keras.layers.Dense(200,name='FullyConnected', activation='relu')(concat)\n",
    "dropout_1 = tf.keras.layers.Dropout(0.2,name='Dropout')(dense)\n",
    "dense_2 = tf.keras.layers.Dense(100,name='FullyConnected-1', activation='relu')(concat)\n",
    "dropout_2 = tf.keras.layers.Dropout(0.2,name='Dropout')(dense_2)\n",
    "dense_3 = tf.keras.layers.Dense(50,name='FullyConnected-2', activation='relu')(dense_2)\n",
    "dropout_3 =tf.keras.layers.Dropout(0.2,name='Dropout')(dense_3)\n",
    "dense_4 = tf.keras.layers.Dense(20,name='FullyConnected-3', activation='relu')(dense_3)\n",
    "\n",
    "result = tf.keras.layers.Dense(1, activation='relu',name='Activation')(dense_4)\n",
    "\n",
    "adam = optimizer = tf.optimizers.Adam( lr=0.0001)\n",
    "model_NN = tf.keras.Model([user_input, item_input], result)\n",
    "model_NN.compile(optimizer=adam,loss= 'mean_absolute_error')\n",
    "model_NN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberEpochs = 20\n",
    "print_log = 0\n",
    "history_NN = model_NN.fit([user_index, item_index], rates, epochs=numberEpochs, verbose=print_log, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_test = compute_RMSE(model_NN, user_index_test, item_index_test)\n",
    "\n",
    "precision = compute_precisionAtK_from_recommendations(model_NN, df_test, validation_set=validation_set, nrRecommendations=20, k=5)\n",
    "print(\"MF: Precision@{} is {}\".format(5, precision))\n",
    "print(\"MF: RMSE is {}\".format(err_test))\n",
    "\n",
    "table.add(name=experiment_name, rmse=err_test, precision=precision, overwrite=True)\n",
    "table.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise NN:\n",
    "Change the model parameters, for example:\n",
    "- Change the number of layers of the NN. \n",
    "- Remove/add dropout\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design a simple baseline:  predict average rate per item and recommend items with the highest rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbo = df_test[[\"item\", \"rate\"]].groupby(\"item\").mean().reset_index()\n",
    "df_gbo = pd.merge(df_test, gbo, on=\"item\", suffixes=('', '_gbo'))\n",
    "display(df_gbo[df_gbo.item == 1].head())\n",
    "predicted_rates_gbo_test = df_gbo.rate_gbo.values\n",
    "\n",
    "err_gbo_test = mean_absolute_error(rates_test + mean_rating_test, predicted_rates_gbo_test)\n",
    "print(\"Mean absolute error on the test set: {}\".format(err_gbo_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_highest_rates(df, userList, nrRecommendations=10):\n",
    "    gbo_set = {}\n",
    "    \n",
    "    # compute mean rating per item\n",
    "    all_items = numpy.unique(df['item'].values)\n",
    "    gbos = df.groupby(\"item\").mean().rate.reset_index().sort_values(by=\"rate\", ascending=False).item.values[:nrRecommendations]\n",
    "    \n",
    "    for user in userList:\n",
    "        gbo_set[user] = gbos\n",
    "            \n",
    "    return gbo_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_rates_baseline = recommend_highest_rates(df, validation_set.keys(), nrRecommendations=20)\n",
    "\n",
    "precision_baseline = precisionAtK(validation_set, highest_rates_baseline, k=5)\n",
    "print(\"Baseline: Precision@{} is {}\".format(5, precision_baseline))\n",
    "table.add(name=\"gbo\", rmse=err_gbo_test, precision=precision_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(table.df.sort_values(by=\"RMSE\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(table.df.sort_values(by=\"Precision@5\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
