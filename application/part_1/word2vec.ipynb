{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta learning with word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of this notebook is to use Word2Vec in recommendations for MovieLens dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q matplotlib\n",
    "!pip install -q pandas\n",
    "!pip install -q numpy\n",
    "!pip install -q gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "\n",
    "resp = urlopen(\"http://files.grouplens.org/datasets/movielens/ml-100k.zip\")\n",
    "zipfile = ZipFile(BytesIO(resp.read()))\n",
    "file = 'ml-100k/u.data'\n",
    "df = pd.read_csv(zipfile.open(file), low_memory=False, skiprows=[0], sep='\\t', names=['user', 'item', 'rate', 'time'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll get the data and sort by time. The reason of sorting by time is due to the fact that we need the movies that each user saw in chronological order. We also filter movies with ranking above of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "# # split data into train and test set\n",
    "# msk = np.random.rand(len(df)) < 0.7\n",
    "# df_train = df[msk]\n",
    "# df_test = df[~msk]\n",
    "\n",
    "df_train = df\n",
    "\n",
    "df_train['time'] = pd.to_datetime(df_train['time'], unit='s')\n",
    "df_train = df_train.sort_values(by='time')\n",
    "\n",
    "df_train = df_train[df_train['rate'] > 3]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will get the movie features, see the description in http://files.grouplens.org/datasets/movielens/ml-100k-README.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['item', 'movie title', 'release date', 'video release date',\n",
    "              'IMDb URL', 'unknown', 'Action', 'Adventure', 'Animation',\n",
    "              'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "              'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',\n",
    "              'Thriller', 'War', 'Western' ]\n",
    "\n",
    "file_item = 'ml-100k/u.item'\n",
    "\n",
    "df_items = pd.read_csv(zipfile.open(file_item), names= names, sep='|', encoding = 'ISO-8859-1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = df_items.filter(['item', 'movie title', 'Action', 'Adventure', 'Animation',\n",
    "              'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "              'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',\n",
    "              'Thriller', 'War', 'Western'])\n",
    "display(df_items.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge the training dataset in order to have items with genre. We look at all the items watched by user '914'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_extended = pd.merge(df_train, df_items, on='item')\n",
    "\n",
    "\n",
    "display(df_train_extended[df_train_extended['user'] == 914])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a dataset with all the users and all their watched films sorted by timestamp. Also we'll add the first genre that is related to each movie. Note that a movie can have several genres but this is to keep the example simple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genrelist = ['Action', 'Adventure', 'Animation', \n",
    "    'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "    'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',\n",
    "    'Thriller', 'War', 'Western']\n",
    "\n",
    "def get_features_movie(item_id):\n",
    "    features = []\n",
    "    row = df_items[df_items['item'] == item_id]\n",
    "    for i in genrelist:\n",
    "        if row.iloc[0][i]:\n",
    "            features = features + [i]\n",
    "    return features\n",
    "\n",
    "\n",
    "display(df_items[df_items['item'] == 402])\n",
    "get_features_movie(402)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list(item_id):\n",
    "    return \" \".join([str(x) for x in get_features_movie(item_id)[:1]])\n",
    "convert_to_list(402)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the word2vec training set\n",
    "train_watched = pd.DataFrame(columns=['user', 'watched'])\n",
    "\n",
    "for index, user_id in enumerate(range(min(df_train_extended['user']), max(df_train_extended['user']))):\n",
    "    user_itemslist = df_train_extended[df_train_extended['user'] == user_id].item.values\n",
    "    \n",
    "    l_to_string = \" \".join([convert_to_list(x)+\" \"+str(x) for x in user_itemslist])\n",
    "    train_watched.loc[index] = [user_id, l_to_string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_watched.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the new dataset we can see for every user the watched films and the genre for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_doc = []\n",
    "\n",
    "for row in train_watched.to_dict(orient='record'):\n",
    "    list_doc.append(str(row['watched']).strip().split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_doc[2])\n",
    "len(list_doc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(list_doc, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(item_id_or_genre):\n",
    "    try:\n",
    "        print(\"Similar of \"+df_items[df_items['item'] == int(item_id_or_genre)].iloc[0]['movie title'])\n",
    "    except:\n",
    "        print(\"Similar of \"+item_id_or_genre)\n",
    "    return [(x, df_items[df_items['item'] == int(x[0])].iloc[0]['movie title']) for x in model.wv.most_similar(item_id_or_genre)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the most similar movies to 'Action' genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar('Action')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar('402')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar('Horror')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to create recommendations for a user. For example, this is what user 914 saw:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train_extended[df_train_extended['user'] == 914].filter(['item', 'movie title']+genrelist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to define a user embedding is to average the embeddings of movies that he/she saw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_avg_user_vector(user_id):\n",
    "    item_id_list = df_train_extended[df_train_extended['user'] == user_id]['item'].tolist()\n",
    "    vector_item_id_list = [model.wv[str(x)] for x in item_id_list]\n",
    "    return np.average(vector_item_id_list, axis=0)\n",
    "\n",
    "def most_similar_by_vector(vector):\n",
    "    return [(x, df_items[df_items['item'] == int(x[0])].iloc[0]['movie title']) for x in model.wv.similar_by_vector(vector)]\n",
    "\n",
    "\n",
    "recomendations = most_similar_by_vector(create_avg_user_vector(914))\n",
    "display(pd.DataFrame(recomendations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[int(r[0]) for r in model.wv.similar_by_vector(create_avg_user_vector(914))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions: Evaluate precision@k on the test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate recommendations from the trained model for a list of users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and compute Precision@K score\n",
    "\n",
    "We first create a validation set for every user which consists of all the products that the user rated higher than 3.5 (the value of the mean rate).\n",
    "\n",
    "We then compute precistion@K for our recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create validation set for every user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_validation_set(df, minRate=3.5, k=5):\n",
    "    validation_set = {}\n",
    "    \n",
    "    for user in np.unique(df['user'].values) :\n",
    "        rated_items = df[df['user'] == user]['item'].values \n",
    "        rates = df[df['user'] == user]['rate'].values\n",
    "\n",
    "        best_ranked_items = rated_items[np.where(rates > minRate)[0]]\n",
    "        if len(best_ranked_items) >= k:\n",
    "            validation_set[user] = best_ranked_items\n",
    "            \n",
    "    return validation_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Compute precision@k using the recommendations and the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precisionAtK(validations_set, recommendations_set, k=5):\n",
    "    \n",
    "    res = []\n",
    "    for user in validations_set.keys():\n",
    "        \n",
    "        v = validations_set[user]\n",
    "        r = recommendations_set[user][:k]\n",
    "        \n",
    "        ans = len(np.intersect1d(v, r)) / k\n",
    "        res.append(ans)\n",
    "\n",
    "    return np.mean(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precisionAtK_from_recommendations(model, df_test, validation_set=None, nrRecommendations=20, k=10):\n",
    "    \"\"\"\n",
    "    Compute precisionAtK from recommendations and validation set. Generate recommendations applying \\\n",
    "    'model' to dataset 'df_test'. \n",
    "    \"\"\"\n",
    "    if validation_set is None:\n",
    "        validation_set = create_validation_set(df_test, minRate=3.5, k=k)\n",
    "        \n",
    "    recommendations_set = create_recommendations(model, df_test, \\\n",
    "                                              validation_set.keys(), nrRecommendations=nrRecommendations)\n",
    "    precision = precisionAtK(validation_set, recommendations_set, k=k)\n",
    "    \n",
    "    return precision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_recommendations(model, df, listOfUsers, nrRecommendations=20):\n",
    "    \n",
    "    recommendations_set = {}\n",
    "    for user in listOfUsers:\n",
    "        r = []\n",
    "        for rr in model.wv.similar_by_vector(create_avg_user_vector(user)):\n",
    "            try:\n",
    "                r.append(int(rr[0]))\n",
    "            except:\n",
    "                pass\n",
    "        recommendations_set[user] = r\n",
    "        \n",
    "    return recommendations_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = create_validation_set(df_train_extended, minRate=3.5)\n",
    "\n",
    "precision = compute_precisionAtK_from_recommendations(model, df_train_extended, validation_set=validation_set, nrRecommendations=20, k=5)\n",
    "print(\"MF: Precision@{} is {}\".format(5, precision))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
