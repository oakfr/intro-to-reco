{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNNs for next product prediction\n",
    "\n",
    "The goal of this notebook is to look at a simple implementation of RNN for next product prediction.\n",
    "It might seem as an obvious use case, but it wasn't very popular until the 2015 paper [Session-based Recommendations with Recurrent Neural Networks](https://arxiv.org/abs/1511.06939).\n",
    "\n",
    "We will be using a sample of the [RecSys 2015 challenge yoochoose dataset](https://2015.recsyschallenge.com/challenge.html), where we will user click sessions of various lengths, and the task we will be trying to solve, is predicting at each timestep the next product the user will click."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import collections\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "import sys\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import *\n",
    "from keras import Sequential\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need now to load the data from a url. We will several sessions, where a session is a succession of clicks on products, basically a shopping session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df_from_url(path):\n",
    "    sessions_df = pd.read_csv(path, sep=\",\", header=None)\n",
    "    sessions_df.columns = [\"session_id\", \"timestamp\", \"item_id\", \"category\"]\n",
    "    sessions_df[\"timestamp\"] = pd.to_datetime(sessions_df[\"timestamp\"])\n",
    "    return sessions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"https://www.dropbox.com/s/urf0v28umc7afg2/yoochoose-clicks-sample.dat?dl=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_df = load_df_from_url(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will build the actual sessions which just a list of products. We will group rows by session_id, replace product ids with their indices (between 1 and product_vocab_size, we will see why we are 1-indexed later), and filter out products that are not very common and sessions that are too small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sessions(sessions_df: pd.DataFrame, \n",
    "                   max_products: int = 1000, \n",
    "                   min_session_size: int = 3) -> List[List[int]]:\n",
    "    print(\"Session Dataframe length \", len(sessions_df))\n",
    "    \n",
    "    all_items = sessions_df[\"item_id\"].values\n",
    "    items_counter = collections.Counter(all_items)\n",
    "    most_common_items = dict(items_counter.most_common(max_products))\n",
    "    ids_to_indices = dict((item_id, i+1) for i, item_id in enumerate(most_common_items.keys()))\n",
    "    \n",
    "    session_dicts = sessions_df.to_dict(orient='records')\n",
    "    grouped_sessions = itertools.groupby(session_dicts, lambda d: d[\"session_id\"])\n",
    "    sessions = []\n",
    "    for _, session in grouped_sessions:\n",
    "        item_list = [d[\"item_id\"] for d in sorted(list(session), key=lambda x: x[\"timestamp\"])]\n",
    "        item_list = [ids_to_indices[item] for item in item_list if item in ids_to_indices]\n",
    "        if len(item_list) >= min_session_size:\n",
    "            sessions.append(item_list)\n",
    "    \n",
    "    print(\"Sessions count \", len(sessions))\n",
    "    \n",
    "    return sessions, most_common_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions, most_common_items = build_sessions(sessions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't have sessions of different lengths in the same tensor (or numpy array). So we need to fix a session length and truncate sessions to this length, or pad them with a dummy value, we will use 0 as our dummy value, and that is why we adopted 1-based indexing previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_session_length = 50\n",
    "padded_sessions = pad_sequences(sessions, \n",
    "                                maxlen=max_session_length, \n",
    "                                padding='post', \n",
    "                                truncating='pre', \n",
    "                                value=0)\n",
    "padded_sessions = np.array(padded_sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a very simple LSTM model, where we will first embed the products in a lower dimensional space and then use the output of the LSTM at each timestep to predict the next product in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(most_common_items) + 1\n",
    "embedding_size = 20\n",
    "input_length = max_session_length - 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0, input_shape=(input_length, )))\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=input_length, mask_zero=True))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement a custom metric here as we want the accuracy for the whole sequence while masking the dummy value 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy_sequential(y_true, y_pred):\n",
    "    y_true = tf.squeeze(y_true)\n",
    "    padding_mask = tf.greater(y_true, 0)\n",
    "    \n",
    "    y_pred = tf.argmax(y_pred, axis=-1)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    match = tf.cast(tf.equal(y_true, y_pred), tf.float32)\n",
    "\n",
    "    match_masked = match * tf.cast(padding_mask, tf.float32)\n",
    "    return tf.reduce_sum(match_masked) / tf.reduce_sum(tf.cast(padding_mask, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = padded_sessions[:, :-1]\n",
    "y = np.expand_dims(padded_sessions[:, 1:], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[categorical_accuracy_sequential])\n",
    "model.fit(x=X, y=y, validation_split=0.1, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "* Q1 : Try increasing the max sequence length (from 50 to 100) what's the impact on the performance ? How about the maximum number of unique products ?\n",
    "* Q2 : Let's make the model bigger ! Try adding a second (or more) LSTM layers\n",
    "* Q3 : Compare the performance of the model to a naive model that always predict the current product as the next product (in other words y_pred = X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
